{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3888888888888893"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from url_delect import parse_url\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\action_log1601.csv', sep='--->', \n",
    "                header = None, engine='python', iterator = True,\n",
    "                names = ['uuid', 'uid', 'ref', 'url', 'time', 'ip'])\n",
    "    df = f.get_chunk(300)\n",
    "    return df\n",
    "\n",
    "\n",
    "def reserve_time():\n",
    "    df = df_set()\n",
    "    r_time = {}\n",
    "    for k, v in df.groupby([df['uuid'], df['time']]):\n",
    "        for url in v['url']:\n",
    "            url = parse_url(url)\n",
    "            if re.match(r'.*reserve', url):\n",
    "                r_time[k[0]] = r_time.get(k[0], []) + [k[1]]\n",
    "    return r_time\n",
    "\n",
    "\n",
    "def first_time():\n",
    "    df = df_set()\n",
    "    reserve_data = reserve_time()\n",
    "    f_time = {}\n",
    "    for k, v in df.groupby(df['uuid']):\n",
    "        if k in reserve_data.keys():\n",
    "            f_time[k] = [v['time'].tolist()[0],\n",
    "                         reserve_data.get(k)[0]]\n",
    "    return f_time\n",
    "\n",
    "\n",
    "def averge_time(data):\n",
    "    time = np.array([data.get(uuid)[1] - data.get(uuid)[0]\n",
    "                     for uuid in data])\n",
    "    avg_time = time.sum()\n",
    "    return avg_time / time.shape[0]\n",
    "\n",
    "\n",
    "data_set = first_time()\n",
    "averge_time(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667 0.471404520791\n"
     ]
    }
   ],
   "source": [
    "from ncode import NCode\n",
    "from sklearn import neighbors\n",
    "from sklearn import cross_validation\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\action_log1601.csv', sep='--->', \n",
    "                header = None, engine='python', iterator = True,\n",
    "                names = ['uuid', 'uid', 'ref', 'url', 'time', 'ip'])\n",
    "    df = f.get_chunk(10000)\n",
    "    return df\n",
    "\n",
    "\n",
    "def paid_id(uid):\n",
    "    conn = pymysql.connect(host='***',port=3306,user='***',\n",
    "                           passwd='***',db='talk',charset='utf8')\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('''select id,is_buy from user where id = '''+uid+'''\n",
    "                ''')\n",
    "    paid_uid = [col[1] for col in cur]\n",
    "    return paid_uid\n",
    "    \n",
    "\n",
    "def dataset():\n",
    "    df = df_set()\n",
    "    uid = []\n",
    "    for k, v in df.groupby(df['uid']):\n",
    "        k = NCode().decode(k)\n",
    "        time = v['time'].tolist()[-1] - v['time'].tolist()[0]\n",
    "        if paid_id(k)[0] == 'buy':\n",
    "            uid.append([time, 1])\n",
    "        else:\n",
    "            uid.append([time, 0])\n",
    "    return np.array(uid)\n",
    "\n",
    "\n",
    "x = dataset()[:, :1]\n",
    "y = dataset()[:, 1]\n",
    "scores = []\n",
    "rs = cross_validation.ShuffleSplit(4, n_iter=3, test_size=.25, random_state=0)\n",
    "for train, test in rs:\n",
    "    x_train, x_test = x[train], x[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    model = neighbors.KNeighborsClassifier()\n",
    "    model.fit(x, y)\n",
    "    scores.append(model.score(x_test, y_test))\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import cross_validation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\page_step.csv', sep='|', \n",
    "                header = None, iterator = True,\n",
    "                names = ['UserID', 'ClickDate', 'TimeOnPage', 'VisitStepID'])\n",
    "    df = f.get_chunk(30000)\n",
    "    return df\n",
    "\n",
    "\n",
    "def user_data():\n",
    "    df = df_set()\n",
    "    time = []\n",
    "    for k, v in df.groupby('UserID'):\n",
    "        if k == 0: continue\n",
    "        mean_time = np.mean(v['TimeOnPage'].tolist())\n",
    "        if mean_time == -1: continue\n",
    "            \n",
    "        if mean_time < 100:\n",
    "            time.append([mean_time, 1])\n",
    "        else:\n",
    "            time.append([mean_time, 0])\n",
    "    return np.array(time)\n",
    "\n",
    "\n",
    "x = user_data()[:, :1]\n",
    "y = user_data()[:, 1]\n",
    "scores = []\n",
    "rs = cross_validation.ShuffleSplit(4, n_iter=3, test_size=.25, random_state=0)\n",
    "for train, test in rs:\n",
    "    x_train, x_test = x[train], x[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    clf = neighbors.KNeighborsClassifier()\n",
    "    clf.fit(x, y)\n",
    "    scores.append(clf.score(x_test, y_test))\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import re\n",
    "from datetime import datetime,date,timedelta\n",
    "\n",
    "#user_analysis\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\page_step_new_2.csv', sep='*', \n",
    "                header = None, iterator = True, encoding = 'latin1', dtype='unicode',\n",
    "                names = ['uid', 'ref', 'url', 'click_date', 'time_page', 'step'])\n",
    "    df = f.get_chunk(14659399) #total rows: 14659399\n",
    "    df[['time_page', 'step']] = df[['time_page', 'step']].astype(float)\n",
    "    df['time_page'] = df['time_page'].replace(-1, 0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_teacher(df):\n",
    "    pattern_teacher = re.compile(r'.*/teacher/[a-z]+/[a-z0-9]')\n",
    "    #pattern = re.compile(r'.*/reserve/')\n",
    "    #pattern_tool = re.compile(r'.*/trial/tool')\n",
    "    #pattern_product = re.compile(r'.*/pay/product')\n",
    "    #pattern_pay = re.compile(r'.*/pay/(?:order|orderPay)')\n",
    "    #pattern_index_www = re.compile(r'.*://(www\\.51talk\\.(com|cn|net))($|/landing)')\n",
    "    #pattern_index_wap = re.compile(r'.*://(wap\\.51talk\\.(com|cn|net))($|/landing)')\n",
    "    #pattern_user_info = re.compile(r'.*/user/info')\n",
    "    type_url = []\n",
    "    for url in df['url']:\n",
    "        if pattern_teacher.match(url):\n",
    "            type_url.append('teacher')\n",
    "        #elif pattern_tool.match(url):\n",
    "        #    type_url.append('tool')\n",
    "        #elif pattern_product.match(url):\n",
    "        #    type_url.append('product')\n",
    "        #elif pattern_pay.match(url):\n",
    "        #    type_url.append('pay')\n",
    "        #elif pattern_index_www.match(url):\n",
    "        #    type_url.append('index_www')\n",
    "        #elif pattern_index_wap.match(url):\n",
    "        #    type_url.append('index_wap')\n",
    "        #elif pattern_user_info.match(url):\n",
    "        #    type_url.append('user_info')   \n",
    "        else:\n",
    "            type_url.append('--')            \n",
    "    df['type_url'] = type_url\n",
    "    df_teacher = df[df['type_url']=='teacher']\n",
    "    return df_teacher\n",
    "\n",
    "\n",
    "def search_t(df):\n",
    "    df = df.copy()\n",
    "    teacher_list = []\n",
    "    pattern = re.compile(r'.*/teacher/[a-z]+/([a-z0-9]+)')\n",
    "    for index, row in df.iterrows():\n",
    "        m = pattern.match(row['url'])\n",
    "        teacher_list.append(m.group(1))\n",
    "    df['t_id'] = teacher_list\n",
    "    return df\n",
    "\n",
    "\n",
    "def resault_student(df):\n",
    "    grouped = df.groupby('uid')\n",
    "    step_data = [[k, v['step'].sum()] for k, v in grouped]\n",
    "    time_page_data = [[k, v['time_page'].sum()] for k, v in grouped]\n",
    "    \n",
    "    resault1 = pd.DataFrame(step_data, columns=['uid', 'step_total'])\n",
    "    resault2 = pd.DataFrame(time_page_data, columns=['uid', 'time_total'])\n",
    "    resault = pd.merge(resault1, resault2, how='outer', on='uid')\n",
    "    return resault\n",
    "    #resault.to_csv('D:/luzheng/桌面/student_page_time.csv')\n",
    "\n",
    "    \n",
    "def student_dis(df):\n",
    "    uid = df['uid'].tolist()\n",
    "    conn = pymysql.connect(host='***',port=3306,user='***',\n",
    "                           passwd='***',db='talk',charset='utf8')\n",
    "    cur = conn.cursor(pymysql.cursors.SSCursor)\n",
    "    cur.execute('''select id, sex, age, is_buy, city, is_staff, birthday from user\n",
    "                   where id in ('''+\",\".join(uid)+''')\n",
    "                ''')\n",
    "    user_data = [[str(row[0]), row[1], row[2], \n",
    "                  row[3], row[4], row[5], row[6]] for row in cur]\n",
    "        \n",
    "    df_user = pd.DataFrame(user_data, columns=['uid', 'sex', 'age', \n",
    "                                               'buy_type', 'city','staff_type','birthday'])\n",
    "    df_stu = pd.merge(df, df_user, how='left', on='uid')\n",
    "    \n",
    "    df_stu['age'].fillna(0, inplace = True)\n",
    "    df_stu['sex'].fillna('-', inplace = True)\n",
    "    df_stu['city'].fillna('未知', inplace = True)\n",
    "    df_stu['city'] = df_stu['city'].replace('', '未知')\n",
    "    df_stu['birthday'] = pd.to_datetime(df_stu['birthday'], errors='coerce')\n",
    "    df_stu['age_new'] = pd.datetime.now().year - df_stu['birthday'].dt.year\n",
    "    \n",
    "    return df_stu\n",
    "    #df_stu.to_csv('D:/luzheng/桌面/student_data.csv', encoding='utf-8')\n",
    "    \n",
    "\n",
    "def resault_teacher(df):\n",
    "    grouped = df.groupby('t_id')\n",
    "    data = []\n",
    "    for k, v in grouped:\n",
    "        stu_count = len(set(v['uid'].tolist()))\n",
    "        total_time = v['time_page'].sum()\n",
    "        \n",
    "        data.append([k, stu_count, total_time])\n",
    "        resault = pd.DataFrame(data, columns=['t_id', 'stu_count', 'page_time'])\n",
    "        resault.sort_values('page_time', ascending=0).to_csv('D:/luzheng/桌面/teacher_page_time.csv')\n",
    "\n",
    "        \n",
    "#teacher_resault\n",
    "df_t = df_teacher(df_set())\n",
    "df = search_t(df_t)\n",
    "resault_teacher(df)\n",
    "\n",
    "#student_resault\n",
    "#resault_student(df_set())\n",
    "#student_dis(resault_student(df_set()))\n",
    "\n",
    "\n",
    "#count_stu\n",
    "#df.groupby(['t_id', 'uid']).sum().sort('time_page').to_csv('D:/luzheng/桌面/teacher_page_time_2.csv')\n",
    "\n",
    "#piovt_table\n",
    "#pd.pivot_table(df, index = ['url', 'uid', 'click_date'],\n",
    "#                values = ['time_page'], aggfunc = [np.sum], fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import re\n",
    "from datetime import datetime,date,timedelta\n",
    "\n",
    "#user_analysis_student\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\page_step_new_3.csv', sep='*', \n",
    "                header = None, iterator = True, encoding = 'latin1', dtype='unicode',\n",
    "                names = ['uid', 'ref', 'url', 'click_date','click_date_time', 'time_page', 'step'])\n",
    "    df = f.get_chunk(201070) #total rows: 201070\n",
    "    df[['time_page', 'step']] = df[['time_page', 'step']].astype(float)\n",
    "    df['time_page'] = df['time_page'].replace(-1, 0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def resault_student(df):\n",
    "    grouped = df.groupby('uid')\n",
    "    step_data = [[k, v['step'].sum()] for k, v in grouped]\n",
    "    time_page_data = [[k, v['time_page'].sum()] for k, v in grouped]\n",
    "    \n",
    "    resault1 = pd.DataFrame(step_data, columns=['uid', 'step_total'])\n",
    "    resault2 = pd.DataFrame(time_page_data, columns=['uid', 'time_total'])\n",
    "    resault = pd.merge(resault1, resault2, how='outer', on='uid')\n",
    "    return resault\n",
    "    #resault.to_csv('D:/luzheng/桌面/student_page_time.csv')\n",
    "\n",
    "    \n",
    "def student_dis(df):\n",
    "    uid = df['uid'].tolist()\n",
    "    conn = pymysql.connect(host='***',port=3306,user='***',\n",
    "                           passwd='***',db='talk',charset='utf8')\n",
    "    cur = conn.cursor(pymysql.cursors.SSCursor)\n",
    "    cur.execute('''select id, sex, age, is_buy, city, is_staff, birthday from user\n",
    "                   where id in ('''+\",\".join(uid)+''')\n",
    "                ''')\n",
    "    user_data = [[str(row[0]), row[1], row[2], \n",
    "                  row[3], row[4], row[5], row[6]] for row in cur]\n",
    "        \n",
    "    df_user = pd.DataFrame(user_data, columns=['uid', 'sex', 'age', \n",
    "                                               'buy_type', 'city','staff_type','birthday'])\n",
    "    df_stu = pd.merge(df, df_user, how='left', on='uid')\n",
    "    \n",
    "    df_stu['age'].fillna(0, inplace = True)\n",
    "    df_stu['sex'].fillna('-', inplace = True)\n",
    "    df_stu['city'].fillna('未知', inplace = True)\n",
    "    df_stu['city'] = df_stu['city'].replace('', '未知')\n",
    "    df_stu['birthday'] = pd.to_datetime(df_stu['birthday'], errors='coerce')\n",
    "    df_stu['age_new'] = pd.datetime.now().year - df_stu['birthday'].dt.year\n",
    "    \n",
    "    #return df_stu\n",
    "    df_stu.to_csv('D:/luzheng/桌面/student_data_2.csv', encoding='utf-8')\n",
    "    \n",
    "\n",
    "#student_resault\n",
    "#resault_student(df_set())\n",
    "#student_dis(resault_student(df_set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'http://www.51talk.com/reserve/success'}) ---> frozenset({'http://www.51talk.com/reserve/course'}) conf: 0.7077226606538896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({'http://www.51talk.com/reserve/success'}),\n",
       "  frozenset({'http://www.51talk.com/reserve/course'}),\n",
       "  0.7077226606538896)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#apriori with user_analysis\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\page_step_new_2.csv', sep='*', \n",
    "                header = None, iterator = True, encoding = 'latin1', dtype='unicode',\n",
    "                names = ['uid', 'ref', 'url', 'click_date', 'time_page', 'step'])\n",
    "    df = f.get_chunk(100000) #total rows: 14659399\n",
    "    #df[['time_page', 'step']] = df[['time_page', 'step']].astype(float)\n",
    "    #df['time_page'] = df['time_page'].replace(-1, 0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    df = df_set()\n",
    "    ref_url = [[row['ref'], row['url']]\n",
    "               for index, row in df.iterrows()] #遍历df转换2维列表\n",
    "    return np.array(ref_url)\n",
    "\n",
    "    \n",
    "def create_c1(data_set):\n",
    "    c1 = []\n",
    "    for row in data_set:\n",
    "        for col in row:\n",
    "            if [col] not in c1:           #对列表元素去重\n",
    "                c1.append([col])\n",
    "    c1.sort()\n",
    "    return list(map(frozenset, c1))       #创建不变集合\n",
    "            \n",
    "\n",
    "def scan_d(d, c1, minsupport):\n",
    "    sscnt = {}\n",
    "    for d_row in d:\n",
    "        for c_row in c1:\n",
    "            if c_row.issubset(d_row):        #若c是d的子集\n",
    "                if c_row not in sscnt: \n",
    "                    sscnt[c_row] = 1        #frozenset作为字典键\n",
    "                else:\n",
    "                    sscnt[c_row] += 1\n",
    "                    \n",
    "    num_d = float(len(d))\n",
    "    ret_list = []\n",
    "    support_data = {}\n",
    "    for key in sscnt:\n",
    "        support = sscnt[key] / num_d      #计算支持度\n",
    "        if support >= minsupport:\n",
    "            ret_list.insert(0, key)\n",
    "            \n",
    "        support_data[key] = support\n",
    "    return ret_list, support_data\n",
    "\n",
    "\n",
    "def apriori_gen(lk, k):\n",
    "    ret_list = []\n",
    "    lenlk = len(lk)\n",
    "    for i in range(lenlk):\n",
    "        for j in range(i+1, lenlk):\n",
    "            l1 = list(lk[i])[:k-2]\n",
    "            l2 = list(lk[j])[:k-2]\n",
    "            l1.sort()\n",
    "            l2.sort()\n",
    "            if l1 == l2:\n",
    "                ret_list.append(lk[i] | lk[j])\n",
    "    return ret_list\n",
    "\n",
    "\n",
    "def apriori(data_set, minsupport=0.02):\n",
    "    c1 = create_c1(data_set)\n",
    "    d = list(map(set, data_set))\n",
    "    l1, suppdata = scan_d(d, c1, minsupport)\n",
    "    l = [l1]\n",
    "    k = 2\n",
    "    while (len(l[k-2]) > 0):\n",
    "        ck = apriori_gen(l[k-2], k)\n",
    "        lk, supk = scan_d(d, ck, minsupport)\n",
    "        suppdata.update(supk)\n",
    "        l.append(lk)\n",
    "        k += 1\n",
    "    return l, suppdata\n",
    "\n",
    "\n",
    "def calc_conf(freqset, h, supportdata, brl, minconf=0.5):\n",
    "    prunedh = []\n",
    "    for conseq in h:\n",
    "        conf = supportdata[freqset] / supportdata[freqset - conseq]\n",
    "        if conf >= minconf:\n",
    "            print(freqset-conseq, '--->', conseq, 'conf:', conf)\n",
    "            brl.append((freqset-conseq, conseq, conf))\n",
    "            prunedh.append(conseq)\n",
    "    return prunedh\n",
    "\n",
    "\n",
    "def rules_from_conseq(freqset, h, supportdata, brl, minconf=0.5):\n",
    "    m = len(h[0])\n",
    "    if len(freqset) > (m + 1):\n",
    "        hmp1 = apriori_gen(h, m + 1)\n",
    "        hmp1 = calc_conf(freqset, hmp1, supportdata, brl, minconf)\n",
    "        if len(hmp1) > 1:\n",
    "            rules_from_conseq(freqset, hmp1, supportdata, brl, minconf)\n",
    "    \n",
    "\n",
    "def rules(l, suppdata, minconf = 0.5):\n",
    "    rule_list = []\n",
    "    for i in range(1, len(l)):\n",
    "        for freqset in l[i]:\n",
    "            h1 = [frozenset([item]) for item in freqset]\n",
    "            if i > 1:\n",
    "                rules_from_conseq(freqset, h1, suppdata, rule_list, minconf)\n",
    "            else:\n",
    "                calc_conf(freqset, h1, suppdata, rule_list, minconf)\n",
    "    return rule_list\n",
    "    \n",
    "\n",
    "l, suppdata = apriori(load_data())\n",
    "rules = rules(l, suppdata, minconf=0.5)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 32), match='iPhone / iOS 7.1.2 / xiaodurobot'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from user_agents import parse\n",
    "import re\n",
    "\n",
    "ua_string = 'Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like Mac OS X) AppleWebKit/537.51.2 (KHTML, like Gecko) Mobile/537.36 xiaodurobot'\n",
    "user_agent = parse(str(ua_string))\n",
    "\n",
    "user_agent.is_mobile\n",
    "match = re.match(r'(.*)/\\s(\\w+)\\s.*/\\s(.*?)(?:$|\\d)', str(user_agent))    \n",
    "match\n",
    "#str(user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from user_agents import parse\n",
    "import re\n",
    "import pymysql\n",
    "import numpy as np\n",
    "\n",
    "#user_analysis_student\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\page_step_new_4.csv', sep='$', \n",
    "                header = None, iterator = True, encoding = 'latin1', dtype='unicode',\n",
    "                names = ['uid', 'ref', 'url', 'click_date',\n",
    "                         'click_date_time', 'time_page',\n",
    "                         'agent', 'step'])\n",
    "    \n",
    "    df = f.get_chunk(201070) #total rows: 201070\n",
    "    df[['time_page', 'step']] = df[['time_page', 'step']].astype(float)\n",
    "    df['time_page'] = df['time_page'].replace(-1,0)\n",
    "       \n",
    "    for index, row in df.iterrows():\n",
    "        user_agent = parse(str(row['agent']))\n",
    "        agent = re.match(r'(.*)/(.*)/(.*)', str(user_agent))\n",
    "        df.loc[index, 'first_device_type'] = agent.group(1)\n",
    "        df.loc[index, 'first_system'] = agent.group(2)\n",
    "        df.loc[index, 'first_browser'] = agent.group(3)\n",
    "    return df\n",
    "\n",
    "\n",
    "def resault_student(df):\n",
    "    df.drop('agent', axis=1)\n",
    "    time_d = df['time_page'].groupby(df['uid']).sum().reset_index()\n",
    "    step_d = df['step'].groupby(df['uid']).sum().reset_index()\n",
    "    \n",
    "    url_d = []\n",
    "    for k, v in df.groupby(df['uid']):\n",
    "        if len(v['url'].tolist()) == 1:\n",
    "            url_d.append([k, '-'])\n",
    "        else:\n",
    "            url_d.append([k, v['url'].tolist()[1]])\n",
    "            \n",
    "    time_df = pd.DataFrame(time_d)\n",
    "    step_df = pd.DataFrame(step_d)\n",
    "    url_df = pd.DataFrame(url_d, columns=['uid', 'url_se'])\n",
    "    \n",
    "    step_df.drop(['uid'], axis=1, inplace = True)\n",
    "    time_step_df = pd.concat((time_df, step_df), axis=1)\n",
    "    \n",
    "    cols = ['ref', 'url', 'click_date', \n",
    "            'click_date_time', 'agent',\n",
    "            'time_page', 'step']\n",
    "    \n",
    "    df.drop(cols, axis=1, inplace=True)\n",
    "    df_joined = pd.merge(df, time_step_df, how='left', on='uid')\n",
    "    df_joined = df_joined.drop_duplicates(['uid'])\n",
    "    df_all = pd.merge(df_joined, url_df, how='left', on='uid')\n",
    "    #return df_joined\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def student_dis(df):\n",
    "    uid = df['uid'].tolist()\n",
    "    conn = pymysql.connect(host='***',port=3306,user='***',\n",
    "                           passwd='***',db='talk',charset='utf8')\n",
    "    cur = conn.cursor(pymysql.cursors.SSCursor)\n",
    "    cur.execute('''select id, sex, age, is_buy, city, is_staff, birthday from user\n",
    "                   where id in ('''+\",\".join(uid)+''')\n",
    "                ''')\n",
    "    user_data = [[str(row[0]), row[1], \n",
    "                  row[2], row[3], \n",
    "                  row[4], row[5], \n",
    "                  row[6]] for row in cur]\n",
    "        \n",
    "    df_user = pd.DataFrame(user_data, columns=['uid', 'sex', 'age', \n",
    "                                               'buy_type', 'city',\n",
    "                                               'staff_type','birthday'])\n",
    "    \n",
    "    df_stu = pd.merge(df, df_user, how='left', on='uid')\n",
    "    \n",
    "    df_stu['age'].fillna(0, inplace = True)\n",
    "    df_stu['sex'].fillna('-', inplace = True)\n",
    "    df_stu['city'].fillna('未知', inplace = True)\n",
    "    df_stu['city'] = df_stu['city'].replace('', '未知')\n",
    "    df_stu['birthday'] = pd.to_datetime(df_stu['birthday'], errors='coerce')\n",
    "    df_stu['age_new'] = pd.datetime.now().year - df_stu['birthday'].dt.year    \n",
    "    df_stu.drop(['age','staff_type','birthday'], axis=1, inplace=True)\n",
    "    #return df_stu\n",
    "    df_stu.to_csv('D:/luzheng/桌面/student_data_5.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "student_dis(resault_student(df_set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from user_agents import parse\n",
    "import re\n",
    "import pymysql\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "##page_rate_付费模型\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\page_step_new_4.csv', sep='$', \n",
    "                header = None, iterator = True, encoding = 'latin1', dtype='unicode',\n",
    "                names = ['uid', 'ref', 'url', 'click_date',\n",
    "                         'click_date_time', 'time_page',\n",
    "                         'agent', 'step'])\n",
    "    df = f.get_chunk(201070) #total rows: 201070\n",
    "    \n",
    "    df['hour']= pd.to_datetime(df['click_date_time']).apply(lambda x: x.strftime('%H'))\n",
    "    df['day_of_week'] = pd.to_datetime(df['click_date_time']).dt.dayofweek.apply(dayofweek)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        user_agent = parse(str(row['agent']))\n",
    "        agent = re.match(r'(.*)/\\s+(\\w+)\\s+.*/\\s(.*?)(?:$|\\d)', str(user_agent))\n",
    "        df.loc[index, 'first_system'] = agent.group(2)\n",
    "        df.loc[index, 'first_browser'] = agent.group(3)\n",
    "    \n",
    "    drop_col = [col for col in df.columns \n",
    "                  if col not in ['uid', 'url','hour',\n",
    "                                 'day_of_week', 'first_system', 'first_browser']]\n",
    "    df.drop(drop_col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def dayofweek(x):\n",
    "    days = {0: '周一', 1: '周二', 2: '周三',\n",
    "            3: '周四', 4: '周五', 5: '周六', \n",
    "            6: '周日'}\n",
    "    return days[x]\n",
    "\n",
    "\n",
    "def rate(grouped):\n",
    "    buy_count = grouped['buy_type'].apply(lambda x: 1 if x == 1 else 0).sum()\n",
    "    free_count = grouped['buy_type'].apply(lambda x: 1 if x == 0 else 0).sum()\n",
    "    all_count = buy_count + free_count\n",
    "    rate = buy_count / all_count\n",
    "    return rate, all_count\n",
    "\n",
    "\n",
    "def student_dis(df):\n",
    "    uid = df['uid'].tolist()\n",
    "    conn = pymysql.connect(host=***',port=3306,user='***',\n",
    "                           passwd='***',db='talk',charset='utf8')\n",
    "    cur = conn.cursor(pymysql.cursors.SSCursor)\n",
    "    cur.execute('''select id, sex, age, is_buy, city, is_staff, birthday from user\n",
    "                   where id in ('''+\",\".join(uid)+''')\n",
    "                ''')\n",
    "    user_data = [[str(row[0]), row[1], \n",
    "                  row[2], row[3], \n",
    "                  row[4], row[5], \n",
    "                  row[6]] for row in cur]\n",
    "        \n",
    "    df_user = pd.DataFrame(user_data, columns=['uid',  'sex', \n",
    "                                               'age',  'buy_type', \n",
    "                                               'city', 'staff_type', \n",
    "                                               'birthday'])\n",
    "    df_all = pd.merge(df, df_user, how='left', on='uid')\n",
    "    \n",
    "    df_all['buy_type'] = df_all['buy_type'].replace('free', 0)\n",
    "    df_all['buy_type'] = df_all['buy_type'].replace('buy', 1)\n",
    "    \n",
    "    return df_all\n",
    "\n",
    "\n",
    "def rate_count(df_all):\n",
    "    detail = {}\n",
    "    user_duplicates = []\n",
    "    for k, v in df_all.groupby(df_all['url']):\n",
    "        for uid, btype in zip(v['uid'], v['buy_type']):\n",
    "            detail.setdefault(k,{})[uid] = btype\n",
    "            \n",
    "    for url in detail:\n",
    "        all_count = len(detail[url])\n",
    "        buy_count = []\n",
    "        free_count = []\n",
    "        for uid in detail[url]:\n",
    "            if detail[url].get(uid) == 1:\n",
    "                buy_count.append(uid)\n",
    "            else:\n",
    "                free_count.append(uid)\n",
    "        user_duplicates.append([url, len(buy_count) / all_count, all_count])\n",
    "    df_all_new = pd.DataFrame(user_duplicates, columns = ['url', 'pay_rate', 'all_count'])\n",
    "    #df_all_new = df_all.groupby(['url']).apply(rate).reset_index(name='rate')\n",
    "    #df_all_new['all_count'] = df_all_new['rate'].apply(lambda x: x[1])\n",
    "    #df_all_new['rate'] = df_all_new['rate'].apply(lambda x: x[0])\n",
    "    df_sort = df_all_new.sort_values(['pay_rate'], ascending=False)\n",
    "    #return df_all[['uid','buy_type']].ix[df.url == 'http://www.51talk.com/user/update_pwd']\n",
    "    return df_sort\n",
    "    #return df_sort.to_csv('D:/luzheng/桌面/page_rate2.csv', encoding='utf-8')\n",
    "\n",
    "    \n",
    "def time_count(df_all):\n",
    "    counter = []\n",
    "    for k, v in df_all.groupby(df_all['uid']):\n",
    "        week_max = Counter(v['day_of_week']).most_common(1)[0][0]\n",
    "        hour_max = Counter(v['hour']).most_common(1)[0][0]\n",
    "        counter.append([k, week_max, hour_max])\n",
    "    counter_df = pd.DataFrame(counter, columns=['uid', 'week_max', 'hour_max'])\n",
    "    return counter_df\n",
    "\n",
    "    \n",
    "def statics(grouped):\n",
    "    if grouped.count() == 0:\n",
    "        return {'mean_rate': 0, \n",
    "                'total': 0}\n",
    "    else:\n",
    "        return {'mean_rate':grouped.sum()/ grouped.count(), \n",
    "                'total': grouped.sum()}\n",
    "\n",
    "    \n",
    "def rate_output():\n",
    "    df = student_dis(df_set())\n",
    "    df_sort = rate_count(df)\n",
    "    df_all = pd.merge(df, df_sort, how='left', on='url')\n",
    "\n",
    "    rate = df_all['pay_rate'].groupby(df_all['uid']).apply(statics).unstack()\n",
    "    normal = df_all.groupby(['uid', 'buy_type'],as_index=False).count()\n",
    "\n",
    "    normal.drop([col for col in normal.columns \n",
    "                      if col not in ['uid','buy_type']], axis=1, inplace=True)\n",
    "    normal_joined = normal.join(rate, how='left', on=['uid'])\n",
    "    return normal_joined\n",
    "    #normal_joined.to_csv('D:/luzheng/桌面/student_data_6.csv', encoding='utf-8')\n",
    "\n",
    "    \n",
    "def time_output():\n",
    "    df = student_dis(df_set())\n",
    "    normal = df.groupby(['uid', 'buy_type', \n",
    "                         'first_system', 'first_browser'],as_index=False).count()\n",
    "    normal.drop([col for col in normal.columns \n",
    "                       if col not in ['uid', 'buy_type', \n",
    "                                      'first_system', 'first_browser']], axis=1, inplace=True)\n",
    "    \n",
    "    df_time = time_count(df)\n",
    "    df_all = pd.merge(normal, df_time, how='left', on='uid')\n",
    "    return df_all\n",
    "    #df_all.to_csv('D:/luzheng/桌面/student_data_7.csv', encoding='utf-8')\n",
    "\n",
    "    \n",
    "df = time_output()\n",
    "df = df.drop(['buy_type'], axis=1)\n",
    "df_all = pd.merge(df, rate_output(),how='left', on='uid')\n",
    "df_dup = df_all.drop_duplicates(['uid'])\n",
    "df_dup.to_csv('D:/luzheng/桌面/student_data_7.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from user_agents import parse\n",
    "import re\n",
    "import pymysql\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "##page_rate_出席模型\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\page_step_new_6.csv', sep='$', \n",
    "                header = None, iterator = True, encoding = 'latin1', dtype='unicode',\n",
    "                names = ['uid', 'ref', 'url', 'click_date',\n",
    "                         'click_date_time', 'time_page',\n",
    "                         'agent', 'step', 'type'])\n",
    "    df = f.get_chunk(458564) #total rows: 458564\n",
    "    return df\n",
    "    \n",
    "\n",
    "def dayofweek(x):\n",
    "    days = {0: '周一', 1: '周二', 2: '周三',\n",
    "            3: '周四', 4: '周五', 5: '周六', \n",
    "            6: '周日'}\n",
    "    return days[x]\n",
    "\n",
    "\n",
    "def system(x):\n",
    "    user_agent = parse(str(x))\n",
    "    agent = re.match(r'(.*)/\\s+(\\w+)\\s+.*/\\s(.*?)(?:$|\\d)', str(user_agent))\n",
    "    system = agent.group(2)\n",
    "    return system\n",
    "\n",
    "\n",
    "def browser(x):\n",
    "    user_agent = parse(str(x))\n",
    "    agent = re.match(r'(.*)/\\s+(\\w+)\\s+.*/\\s(.*?)(?:$|\\d)', str(user_agent))\n",
    "    browser = agent.group(3)\n",
    "    return browser\n",
    "\n",
    "\n",
    "def date_clean(df):\n",
    "    df['hour']= pd.to_datetime(df['click_date_time']).apply(lambda x: x.strftime('%H'))\n",
    "    df['day_of_week'] = pd.to_datetime(df['click_date_time']).dt.dayofweek.apply(dayofweek)\n",
    "    df['first_system'] = df['agent'].apply(system)\n",
    "    df['first_browser'] = df['agent'].apply(browser)\n",
    "    df['type'] = df['type'].replace('fail', 0)\n",
    "    df['type'] = df['type'].replace('success', 1)\n",
    "        \n",
    "    drop_col = [col for col in df.columns\n",
    "                  if col not in ['uid', 'url', 'hour',\n",
    "                                 'day_of_week', 'first_system', \n",
    "                                 'first_browser', 'type']]\n",
    "    df.drop(drop_col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def rate_count(df_all):\n",
    "    detail = {}\n",
    "    user_duplicates = []\n",
    "    for k, v in df_all.groupby(df_all['url']):\n",
    "        for uid, btype in zip(v['uid'], v['type']):\n",
    "            detail.setdefault(k,{})[uid] = btype\n",
    "            \n",
    "    for url in detail:\n",
    "        all_count = len(detail[url])\n",
    "        success_count = []\n",
    "        fail_count = []\n",
    "        for uid in detail[url]:\n",
    "            if detail[url].get(uid) == 1:\n",
    "                success_count.append(uid)\n",
    "            else:\n",
    "                fail_count.append(uid)\n",
    "        user_duplicates.append([url, len(success_count) / all_count, all_count])\n",
    "    df_all_new = pd.DataFrame(user_duplicates, columns = ['url', 'join_rate', 'all_count'])\n",
    "    df_sort = df_all_new.sort_values(['join_rate'], ascending=False)\n",
    "    return df_sort\n",
    "    #return df_sort.to_csv('D:/luzheng/桌面/page_rate_chuxi.csv', encoding='utf-8')\n",
    "\n",
    "    \n",
    "def time_count(df_all):\n",
    "    counter = []\n",
    "    for k, v in df_all.groupby(df_all['uid']):\n",
    "        week_max = Counter(v['day_of_week']).most_common(1)[0][0]\n",
    "        hour_max = Counter(v['hour']).most_common(1)[0][0]\n",
    "        counter.append([k, week_max, hour_max])\n",
    "    counter_df = pd.DataFrame(counter, columns=['uid', 'week_max', 'hour_max'])\n",
    "    return counter_df\n",
    "\n",
    "    \n",
    "def statics(grouped):\n",
    "    if grouped.count() == 0:\n",
    "        return {'mean_rate': 0, \n",
    "                'total': 0}\n",
    "    else:\n",
    "        return {'mean_rate':grouped.sum()/ grouped.count(), \n",
    "                'total': grouped.sum()}\n",
    "\n",
    "    \n",
    "def rate_output(df):\n",
    "    df_sort = rate_count(df)\n",
    "    df_all = pd.merge(df, df_sort, how='left', on='url')\n",
    "\n",
    "    rate = df_all['join_rate'].groupby(df_all['uid']).apply(statics).unstack()\n",
    "    normal = df_all.groupby(['uid', 'type'],as_index=False).count()\n",
    "\n",
    "    normal.drop([col for col in normal.columns \n",
    "                      if col not in ['uid', 'type']], axis=1, inplace=True)\n",
    "    normal_joined = normal.join(rate, how='left', on=['uid'])\n",
    "    return normal_joined\n",
    "\n",
    "    \n",
    "def time_output(df):\n",
    "    normal = df.groupby(['uid', 'type', \n",
    "                         'first_system', \n",
    "                         'first_browser'],as_index=False).count()\n",
    "    normal.drop([col for col in normal.columns \n",
    "                       if col not in ['uid', 'type', \n",
    "                                      'first_system', \n",
    "                                      'first_browser']], axis=1, inplace=True)\n",
    "    \n",
    "    df_time = time_count(df)\n",
    "    df_all = pd.merge(normal, df_time, how='left', on='uid')\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df = date_clean(df_set())\n",
    "df_time = time_output(df)\n",
    "df_time = df_time.drop(['type'], axis=1)\n",
    "df_all = pd.merge(df_time, rate_output(df),how='left', on='uid')\n",
    "df_dup = df_all.drop_duplicates(['uid'])\n",
    "df_dup.to_csv('D:/luzheng/桌面/student_data_chuxi.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_id</th>\n",
       "      <th>stu_city</th>\n",
       "      <th>stu_sex</th>\n",
       "      <th>stu_type</th>\n",
       "      <th>stu_device</th>\n",
       "      <th>stu_system</th>\n",
       "      <th>stu_browser</th>\n",
       "      <th>stu_page_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18787</td>\n",
       "      <td>('上饶', 2)</td>\n",
       "      <td>('man', 2)</td>\n",
       "      <td>('青少', 2)</td>\n",
       "      <td>('PC ', 2)</td>\n",
       "      <td>(' Windows 7 ', 2)</td>\n",
       "      <td>(' Chrome 31.0.1650', 2)</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11311</td>\n",
       "      <td>('北京', 2)</td>\n",
       "      <td>('man', 2)</td>\n",
       "      <td>('青少', 2)</td>\n",
       "      <td>('PC ', 2)</td>\n",
       "      <td>(' Windows XP ', 2)</td>\n",
       "      <td>(' Chrome 31.0.1650', 2)</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10521</td>\n",
       "      <td>('成都', 2)</td>\n",
       "      <td>('man', 2)</td>\n",
       "      <td>('其他', 2)</td>\n",
       "      <td>('PC ', 2)</td>\n",
       "      <td>(' Windows 10 ', 2)</td>\n",
       "      <td>(' QQ Browser 9.2.5748', 2)</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>387</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16357</td>\n",
       "      <td>('上饶', 3)</td>\n",
       "      <td>('man', 3)</td>\n",
       "      <td>('青少', 3)</td>\n",
       "      <td>('PC ', 3)</td>\n",
       "      <td>(' Windows 7 ', 3)</td>\n",
       "      <td>(' Chrome 31.0.1650', 3)</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12119</td>\n",
       "      <td>('天津', 2)</td>\n",
       "      <td>('man', 2)</td>\n",
       "      <td>('成人', 2)</td>\n",
       "      <td>('PC ', 2)</td>\n",
       "      <td>(' Windows 7 ', 2)</td>\n",
       "      <td>(' Chrome 19.0.1084', 2)</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5439</td>\n",
       "      <td>('天津', 2)</td>\n",
       "      <td>('man', 2)</td>\n",
       "      <td>('成人', 2)</td>\n",
       "      <td>('PC ', 2)</td>\n",
       "      <td>(' Windows 7 ', 2)</td>\n",
       "      <td>(' Chrome 19.0.1084', 2)</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19625</td>\n",
       "      <td>('上饶', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' Chrome 31.0.1650', 1)</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10363</td>\n",
       "      <td>('广州', 7)</td>\n",
       "      <td>('man', 7)</td>\n",
       "      <td>('成人', 7)</td>\n",
       "      <td>('PC ', 7)</td>\n",
       "      <td>(' Windows 8.1 ', 7)</td>\n",
       "      <td>(' Maxthon 4.4.2', 7)</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10102</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('woman', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' Chrome 31.0.1650', 1)</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3496</td>\n",
       "      <td>('武汉', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' Chrome 31.0.1650', 1)</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21701</td>\n",
       "      <td>('上饶', 2)</td>\n",
       "      <td>('man', 2)</td>\n",
       "      <td>('青少', 2)</td>\n",
       "      <td>('PC ', 2)</td>\n",
       "      <td>(' Windows 7 ', 2)</td>\n",
       "      <td>(' Chrome 31.0.1650', 2)</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6423</td>\n",
       "      <td>('上饶', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' Chrome 31.0.1650', 1)</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14589</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4063</td>\n",
       "      <td>('北京', 3)</td>\n",
       "      <td>('man', 3)</td>\n",
       "      <td>('成人', 3)</td>\n",
       "      <td>('PC ', 3)</td>\n",
       "      <td>(' Windows 7 ', 3)</td>\n",
       "      <td>(' Chrome 31.0.1650', 3)</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16008</td>\n",
       "      <td>('上饶', 2)</td>\n",
       "      <td>('man', 2)</td>\n",
       "      <td>('青少', 2)</td>\n",
       "      <td>('PC ', 2)</td>\n",
       "      <td>(' Windows 7 ', 2)</td>\n",
       "      <td>(' Chrome 31.0.1650', 2)</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13266</td>\n",
       "      <td>('酒泉', 1)</td>\n",
       "      <td>('woman', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows XP ', 1)</td>\n",
       "      <td>(' Chrome 31.0.1650', 1)</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21975</td>\n",
       "      <td>('深圳', 3)</td>\n",
       "      <td>('man', 3)</td>\n",
       "      <td>('成人', 3)</td>\n",
       "      <td>('PC ', 3)</td>\n",
       "      <td>(' Windows 7 ', 3)</td>\n",
       "      <td>(' Chrome 46.0.2490', 3)</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12567</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('iPad ', 1)</td>\n",
       "      <td>(' iOS 9.2 ', 1)</td>\n",
       "      <td>(' Mobile Safari 9', 1)</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23427</td>\n",
       "      <td>('南昌', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' QQ Browser 9.2.5748', 1)</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2671</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20390</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('woman', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows XP ', 1)</td>\n",
       "      <td>(' Chrome 45.0.2454', 1)</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6615</td>\n",
       "      <td>('上海', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 49.0.2593', 1)</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4893</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11858</td>\n",
       "      <td>('北京', 1),('深圳', 1)</td>\n",
       "      <td>('man', 2)</td>\n",
       "      <td>('成人', 2)</td>\n",
       "      <td>('PC ', 2)</td>\n",
       "      <td>(' Windows 7 ', 1),(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 46.0.2490', 1),(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5454</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1865</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5752</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' Chrome 31.0.1650', 1)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11644</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4146</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' Chrome 31.0.1650', 1)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6152</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20109</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25459</td>\n",
       "      <td>('佛山', 1)</td>\n",
       "      <td>('-', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' Chrome 40.0.2214', 1)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16372</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('woman', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows XP ', 1)</td>\n",
       "      <td>(' Chrome 45.0.2454', 1)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6594</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows XP ', 1)</td>\n",
       "      <td>(' Chrome 31.0.1650', 1)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11321</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('woman', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows XP ', 1)</td>\n",
       "      <td>(' Chrome 45.0.2454', 1)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23863</td>\n",
       "      <td>('烟台', 1)</td>\n",
       "      <td>('-', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' Chrome 46.0.2490', 1)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20843</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('woman', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 7 ', 1)</td>\n",
       "      <td>(' IE 9', 1)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7273</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('成人', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows 10 ', 1)</td>\n",
       "      <td>(' Chrome 42.0.2311', 1)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9391</td>\n",
       "      <td>('北京', 1)</td>\n",
       "      <td>('man', 1)</td>\n",
       "      <td>('青少', 1)</td>\n",
       "      <td>('PC ', 1)</td>\n",
       "      <td>(' Windows XP ', 1)</td>\n",
       "      <td>(' Chrome 31.0.1650', 1)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     t_id             stu_city       stu_sex   stu_type    stu_device  \\\n",
       "15  18787            ('上饶', 2)    ('man', 2)  ('青少', 2)    ('PC ', 2)   \n",
       "3   11311            ('北京', 2)    ('man', 2)  ('青少', 2)    ('PC ', 2)   \n",
       "2   10521            ('成都', 2)    ('man', 2)  ('其他', 2)    ('PC ', 2)   \n",
       "27    387            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "12  16357            ('上饶', 3)    ('man', 3)  ('青少', 3)    ('PC ', 3)   \n",
       "7   12119            ('天津', 2)    ('man', 2)  ('成人', 2)    ('PC ', 2)   \n",
       "31   5439            ('天津', 2)    ('man', 2)  ('成人', 2)    ('PC ', 2)   \n",
       "16  19625            ('上饶', 1)    ('man', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "1   10363            ('广州', 7)    ('man', 7)  ('成人', 7)    ('PC ', 7)   \n",
       "0   10102            ('北京', 1)  ('woman', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "26   3496            ('武汉', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "20  21701            ('上饶', 2)    ('man', 2)  ('青少', 2)    ('PC ', 2)   \n",
       "35   6423            ('上饶', 1)    ('man', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "10  14589            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "28   4063            ('北京', 3)    ('man', 3)  ('成人', 3)    ('PC ', 3)   \n",
       "11  16008            ('上饶', 2)    ('man', 2)  ('青少', 2)    ('PC ', 2)   \n",
       "9   13266            ('酒泉', 1)  ('woman', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "21  21975            ('深圳', 3)    ('man', 3)  ('成人', 3)    ('PC ', 3)   \n",
       "8   12567            ('北京', 1)    ('man', 1)  ('青少', 1)  ('iPad ', 1)   \n",
       "22  23427            ('南昌', 1)    ('man', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "25   2671            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "18  20390            ('北京', 1)  ('woman', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "37   6615            ('上海', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "30   4893            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "6   11858  ('北京', 1),('深圳', 1)    ('man', 2)  ('成人', 2)    ('PC ', 2)   \n",
       "32   5454            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "14   1865            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "33   5752            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "5   11644            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "29   4146            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "34   6152            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "17  20109            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "24  25459            ('佛山', 1)      ('-', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "13  16372            ('北京', 1)  ('woman', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "36   6594            ('北京', 1)    ('man', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "4   11321            ('北京', 1)  ('woman', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "23  23863            ('烟台', 1)      ('-', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "19  20843            ('北京', 1)  ('woman', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "38   7273            ('北京', 1)    ('man', 1)  ('成人', 1)    ('PC ', 1)   \n",
       "39   9391            ('北京', 1)    ('man', 1)  ('青少', 1)    ('PC ', 1)   \n",
       "\n",
       "                                stu_system  \\\n",
       "15                      (' Windows 7 ', 2)   \n",
       "3                      (' Windows XP ', 2)   \n",
       "2                      (' Windows 10 ', 2)   \n",
       "27                     (' Windows 10 ', 1)   \n",
       "12                      (' Windows 7 ', 3)   \n",
       "7                       (' Windows 7 ', 2)   \n",
       "31                      (' Windows 7 ', 2)   \n",
       "16                      (' Windows 7 ', 1)   \n",
       "1                     (' Windows 8.1 ', 7)   \n",
       "0                       (' Windows 7 ', 1)   \n",
       "26                      (' Windows 7 ', 1)   \n",
       "20                      (' Windows 7 ', 2)   \n",
       "35                      (' Windows 7 ', 1)   \n",
       "10                     (' Windows 10 ', 1)   \n",
       "28                      (' Windows 7 ', 3)   \n",
       "11                      (' Windows 7 ', 2)   \n",
       "9                      (' Windows XP ', 1)   \n",
       "21                      (' Windows 7 ', 3)   \n",
       "8                         (' iOS 9.2 ', 1)   \n",
       "22                      (' Windows 7 ', 1)   \n",
       "25                     (' Windows 10 ', 1)   \n",
       "18                     (' Windows XP ', 1)   \n",
       "37                     (' Windows 10 ', 1)   \n",
       "30                     (' Windows 10 ', 1)   \n",
       "6   (' Windows 7 ', 1),(' Windows 10 ', 1)   \n",
       "32                     (' Windows 10 ', 1)   \n",
       "14                     (' Windows 10 ', 1)   \n",
       "33                      (' Windows 7 ', 1)   \n",
       "5                      (' Windows 10 ', 1)   \n",
       "29                      (' Windows 7 ', 1)   \n",
       "34                     (' Windows 10 ', 1)   \n",
       "17                     (' Windows 10 ', 1)   \n",
       "24                      (' Windows 7 ', 1)   \n",
       "13                     (' Windows XP ', 1)   \n",
       "36                     (' Windows XP ', 1)   \n",
       "4                      (' Windows XP ', 1)   \n",
       "23                      (' Windows 7 ', 1)   \n",
       "19                      (' Windows 7 ', 1)   \n",
       "38                     (' Windows 10 ', 1)   \n",
       "39                     (' Windows XP ', 1)   \n",
       "\n",
       "                                          stu_browser  stu_page_time  \n",
       "15                           (' Chrome 31.0.1650', 2)            292  \n",
       "3                            (' Chrome 31.0.1650', 2)            203  \n",
       "2                         (' QQ Browser 9.2.5748', 2)            196  \n",
       "27                           (' Chrome 42.0.2311', 1)            173  \n",
       "12                           (' Chrome 31.0.1650', 3)            143  \n",
       "7                            (' Chrome 19.0.1084', 2)            129  \n",
       "31                           (' Chrome 19.0.1084', 2)            123  \n",
       "16                           (' Chrome 31.0.1650', 1)             96  \n",
       "1                               (' Maxthon 4.4.2', 7)             69  \n",
       "0                            (' Chrome 31.0.1650', 1)             62  \n",
       "26                           (' Chrome 31.0.1650', 1)             59  \n",
       "20                           (' Chrome 31.0.1650', 2)             59  \n",
       "35                           (' Chrome 31.0.1650', 1)             57  \n",
       "10                           (' Chrome 42.0.2311', 1)             53  \n",
       "28                           (' Chrome 31.0.1650', 3)             45  \n",
       "11                           (' Chrome 31.0.1650', 2)             42  \n",
       "9                            (' Chrome 31.0.1650', 1)             37  \n",
       "21                           (' Chrome 46.0.2490', 3)             37  \n",
       "8                             (' Mobile Safari 9', 1)             35  \n",
       "22                        (' QQ Browser 9.2.5748', 1)             35  \n",
       "25                           (' Chrome 42.0.2311', 1)             31  \n",
       "18                           (' Chrome 45.0.2454', 1)             29  \n",
       "37                           (' Chrome 49.0.2593', 1)             21  \n",
       "30                           (' Chrome 42.0.2311', 1)             18  \n",
       "6   (' Chrome 46.0.2490', 1),(' Chrome 42.0.2311', 1)             17  \n",
       "32                           (' Chrome 42.0.2311', 1)             15  \n",
       "14                           (' Chrome 42.0.2311', 1)             15  \n",
       "33                           (' Chrome 31.0.1650', 1)             12  \n",
       "5                            (' Chrome 42.0.2311', 1)             11  \n",
       "29                           (' Chrome 31.0.1650', 1)             11  \n",
       "34                           (' Chrome 42.0.2311', 1)             11  \n",
       "17                           (' Chrome 42.0.2311', 1)             10  \n",
       "24                           (' Chrome 40.0.2214', 1)              7  \n",
       "13                           (' Chrome 45.0.2454', 1)              6  \n",
       "36                           (' Chrome 31.0.1650', 1)              5  \n",
       "4                            (' Chrome 45.0.2454', 1)              4  \n",
       "23                           (' Chrome 46.0.2490', 1)              0  \n",
       "19                                       (' IE 9', 1)              0  \n",
       "38                           (' Chrome 42.0.2311', 1)              0  \n",
       "39                           (' Chrome 31.0.1650', 1)              0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import re\n",
    "from datetime import datetime,date,timedelta\n",
    "from ncode import NCode\n",
    "from collections import Counter\n",
    "from user_agents import parse\n",
    "\n",
    "#user_analysis\n",
    "\n",
    "\n",
    "def df_set():\n",
    "    f = pd.read_csv('D:\\\\luzheng\\\\桌面\\\\page_step_new.csv', sep='$', \n",
    "                header = None, iterator = True, encoding = 'latin1', dtype='unicode',\n",
    "                names = ['uid', 'ref', 'url', 'click_date',\n",
    "                         'click_time', 'time_page', 'agent',\n",
    "                         'step'])\n",
    "    df = f.get_chunk(1000) #total rows: 14658384\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_teacher(df):\n",
    "    pattern_teacher = re.compile(r'.*/teacher/[a-z]+/[a-z0-9]')\n",
    "    type_url = []\n",
    "    for url in df['url']:\n",
    "        if pattern_teacher.match(url):\n",
    "            type_url.append('teacher')\n",
    "        else:\n",
    "            type_url.append('--')   \n",
    "    df['type_url'] = type_url\n",
    "    df_teacher = df[df['type_url']=='teacher']\n",
    "    return df_teacher\n",
    "\n",
    "\n",
    "def search_t(df):\n",
    "    df = df.copy()\n",
    "    teacher_list = []\n",
    "    pattern = re.compile(r'.*/teacher/[a-z]+/([a-z0-9]+)')\n",
    "    for index, row in df.iterrows():\n",
    "        m = pattern.match(row['url'])\n",
    "        teacher_list.append(NCode().decode(m.group(1)))\n",
    "        #teacher_list.append(m.group(1))\n",
    "    df['t_id'] = teacher_list\n",
    "    return df\n",
    "\n",
    "\n",
    "def removeStopWord(string):\n",
    "    STOP_WORDS = ['省','市','自治区','自治州','自治县','地区','维吾尔','蒙古族','回族','藏族','维吾尔族',\n",
    "              '苗族','彝族','壮族','布依族','朝鲜族','满族','侗族','瑶族','白族','土家族','哈尼族',\n",
    "              '哈萨克族','傣族','黎族','僳僳族','佤族','畲族','高山族','拉祜族','水族','东乡族','纳西族',\n",
    "              '景颇族','柯尔克孜族','土族','达斡尔族','仫佬族','羌族','布朗族','撒拉族','毛南族','仡佬族',\n",
    "              '锡伯族','阿昌族','普米族','塔吉克族','怒族','乌兹别克族','乌孜别克族','俄罗斯族','鄂温克族',\n",
    "              '德昂族','保安族','裕固族','京族','塔塔尔族','独龙族','鄂伦春族','赫哲族','门巴族','珞巴族',\n",
    "              '基诺族']\n",
    "    \n",
    "    if len(string) == 0:\n",
    "        return ''\n",
    "    string = string.strip()\n",
    "    for stop_word in STOP_WORDS:\n",
    "        parts = re.split(stop_word,string)\n",
    "        string = parts[0]\n",
    "    return string\n",
    "\n",
    "\n",
    "def occup(row):\n",
    "    if row in [1, 2, 5]:\n",
    "        row = '成人'\n",
    "    elif row in [3, 4, 6, 7]:\n",
    "        row = '青少'\n",
    "    else:\n",
    "        row = '其他'\n",
    "    return row\n",
    "\n",
    "\n",
    "def device_type(row):\n",
    "    user_agent = parse(str(row))\n",
    "    pattern = re.compile(r'(.*)/(.*)/(.*)')\n",
    "    agent = pattern.match(str(user_agent))\n",
    "    return agent.group(1)\n",
    "\n",
    "\n",
    "def system(row):\n",
    "    user_agent = parse(str(row))\n",
    "    pattern = re.compile(r'(.*)/(.*)/(.*)')\n",
    "    agent = pattern.match(str(user_agent))\n",
    "    return agent.group(2)\n",
    "                      \n",
    "\n",
    "def browser(row):\n",
    "    user_agent = parse(str(row))\n",
    "    pattern = re.compile(r'(.*)/(.*)/(.*)')\n",
    "    agent = pattern.match(str(user_agent))\n",
    "    return agent.group(3)\n",
    "\n",
    "\n",
    "def student_dis(df):\n",
    "    uid = df['uid'].tolist()\n",
    "    conn = pymysql.connect(host='116.213.69.48',port=3306,user='data',\n",
    "                           passwd='Data_0723',db='talk',charset='utf8')\n",
    "    cur = conn.cursor(pymysql.cursors.SSCursor)\n",
    "    cur.execute('''select id, sex, age, is_buy, city, is_staff, birthday, occup\n",
    "                   from user\n",
    "                   where id in ('''+\",\".join(uid)+''')\n",
    "                ''')\n",
    "    user_data = [[str(row[0]), row[1], \n",
    "                  row[2], row[3], \n",
    "                  row[4], row[5], \n",
    "                  row[6], row[7]] for row in cur]\n",
    "    \n",
    "    df_user = pd.DataFrame(user_data, columns=['uid',  'sex', \n",
    "                                               'age',  'buy_type', \n",
    "                                               'city', 'staff_type',\n",
    "                                               'birthday', 'occup'])\n",
    "    \n",
    "    df_all = pd.merge(df, df_user, how='left', on='uid')\n",
    "    df_all['age'].fillna(0, inplace = True)\n",
    "    df_all['sex'].fillna('-', inplace = True)\n",
    "    df_all['city'].fillna('未知', inplace = True)\n",
    "    \n",
    "    df_all['city'] = df_all['city'].apply(removeStopWord)\n",
    "    df_all['occup'] = df_all['occup'].apply(occup)\n",
    "    df_all['device_type'] = df_all['agent'].apply(device_type)\n",
    "    df_all['system'] = df_all['agent'].apply(system)\n",
    "    df_all['browser'] = df_all['agent'].apply(browser)\n",
    "    \n",
    "    df_all['birthday'] = pd.to_datetime(df_all['birthday'], errors='coerce')\n",
    "    df_all['age_new'] = pd.datetime.now().year - df_all['birthday'].dt.year    \n",
    "    \n",
    "    df_all[['time_page', 'step']] = df_all[['time_page', 'step']].astype(float)\n",
    "    df_all['time_page'] = df_all['time_page'].replace(-1, 0)\n",
    "    \n",
    "    df_all.drop(['ref', 'url', 'age', \n",
    "                 'staff_type', 'agent',\n",
    "                 'birthday', 'type_url',\n",
    "                 'step', 'click_date'], axis=1, inplace=True)\n",
    "    return df_all\n",
    "\n",
    "df_t = df_teacher(df_set())\n",
    "df = search_t(df_t)\n",
    "df_new = student_dis(df)\n",
    "detail = []\n",
    "\n",
    "for k, v in df_new.groupby(['t_id']):\n",
    "    city = ','.join(str(v) for v in Counter(v['city']).most_common(3))\n",
    "    sex = ','.join(str(v) for v in Counter(v['sex']).most_common())\n",
    "    occup = ','.join(str(v) for v in Counter(v['occup']).most_common())\n",
    "    device_type = ','.join(str(v) for v in Counter(v['device_type']).most_common(3))\n",
    "    system = ','.join(str(v) for v in Counter(v['system']).most_common(3))\n",
    "    browser = ','.join(str(v) for v in Counter(v['browser']).most_common(3))\n",
    "    page_time = v['time_page'].sum()\n",
    "    detail.append([k, city, sex, occup, \n",
    "                   device_type, system, \n",
    "                   browser, page_time])\n",
    "\n",
    "detail_df = pd.DataFrame(detail, columns=['t_id', 'stu_city', \n",
    "                                          'stu_sex', 'stu_type', \n",
    "                                          'stu_device', 'stu_system',\n",
    "                                          'stu_browser', 'stu_page_time'])\n",
    "\n",
    "time_sort = detail_df.sort_values(['stu_page_time'], ascending=False)\n",
    "\n",
    "time_sort\n",
    "#time_sort.to_csv('D:/luzheng/桌面/teacher_page_time2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
